# HyperScape ğŸš€  
**Hyperspectral Image Classification using Deep Learning**

HyperScape is a deep learning-based project that focuses on classifying hyperspectral images (HSI) by capturing both **spectral and spatial features**. The project explores multiple CNN architectures including a **custom 2D CNN**, **VGG16 with transfer learning**, and a **3D CNN** to achieve high accuracy and generalization across datasets like **Indian Pines** and **Salinas-A**.

---

## ğŸ“Œ Features

- âœ… Custom-built 2D CNN architecture  
- âœ… Transfer learning with VGG16 using PCA-reduced HSI data  
- âœ… 3D CNN for volumetric spectral-spatial analysis  
- âœ… Preprocessing techniques: Band selection, patch extraction, normalization, PCA  
- âœ… Evaluation on Indian Pines; generalization tested on Salinas-A dataset  
- âœ… EarlyStopping and learning rate scheduling for stable training  
- âœ… H5 model and pickle file saving for future inference

---

## ğŸ§  Models Used

| Model         | Highlights                                                  |
|---------------|-------------------------------------------------------------|
| 2D CNN        | Built from scratch; flexible and efficient                  |
| VGG16         | Transfer learning with 3-channel PCA input                  |
| 3D CNN        | Captures detailed spatial + spectral features (Salinas-A)   |

---

## ğŸ“‚ Datasets

- **Indian Pines**:  
  - Size: 145 Ã— 145 pixels  
  - Bands: 224 (200 used)  
  - Classes: 16 land-cover types

- **Salinas-A** *(used for generalization)*:  
  - Size: 83 Ã— 86 pixels  
  - Bands: 204  
  - Classes: 6 vegetation types

Both datasets were captured by the **AVIRIS** sensor.

---

## âš™ï¸ Preprocessing Steps

- Band removal (e.g., water absorption bands)
- Spectral normalization
- PCA for dimensionality reduction (for VGG)
- Patch extraction (e.g., 11Ã—11 or 5Ã—5Ã—30)
- Data augmentation: rotation & flipping

---

## ğŸ—ï¸ Training Details

- **Optimizer**: Adam  
- **Loss Function**: Categorical Crossentropy  
- **Batch Size**: 32  
- **Epochs**: 75  
- **Callbacks**: EarlyStopping, ReduceLROnPlateau  
- **Model Output**: Saved as `.h5`  
- **Test Data**: Saved as `.pkl`

---

## ğŸ“Š Results

- **3D CNN** achieved the **highest accuracy**, generalizing well across unseen data.
- The **hybrid approach** (2D + 3D features) demonstrated strong potential for real-world application.
- Applied to **Hyperion satellite imagery** for urban land classification, supporting **smart city planning** and **environmental monitoring**.

---

| Model      | Accuracy (Indian Pines) | Accuracy (Salinas-A) | Notes                       |
| ---------- | ----------------------- | -------------------- | --------------------------- |
| 2D CNN     | \~93%                   | N/A                  | Good baseline performance   |
| VGG16 (TL) | \~90%                   | N/A                  | Fast training, PCA required |
| 3D CNN     | **\~95%**               | **\~96â€“97%**         | Best spatial-spectral model |

---

## Deployment

This project is deployed on **Hugging Face Spaces** using **Gradio** as the frontend framework.

### ğŸ”— Live App

ğŸ‘‰ [Click here to launch HyperScape](https://huggingface.co/spaces/Ommooley10/HyperScape)

### ğŸ“ Files in Deployment

- `app.py` â€“ Main Python script containing the Gradio interface and model inference logic.
- `requirements.txt` â€“ Lists all required Python dependencies.
- `Models/` â€“ Pretrained 2D and 3D CNN models (e.g., for Indian Pines, Salinas-A).
- `dataset/`- Containing the datasets and their respective RGB images.
- `Test_data/` â€“ Test set data and coordinate points.
- `utils/` â€“ Helper scripts for preprocessing, visualization, and prediction.

### Tech Stack

- **Frontend**: Gradio
- **Backend**: Python (TensorFlow/Keras, NumPy, SciPy, OpenCV, Matplotlib)
- **Platform**: Hugging Face Spaces

### How to Deploy on Hugging Face Spaces

To deploy this app on your own Hugging Face Space:

1. Create a new Space at [huggingface.co/spaces](https://huggingface.co/spaces).
2. Choose **Gradio** as the SDK.
3. Upload the following files to your Space:
   - `app.py`
   - `requirements.txt`
   - Any model/data files your app depends on
4. Click **"Commit"** and the app will build and launch automatically.

Once deployed, the app will be accessible via a public URL and automatically re-run on any code or file updates.

### Status

-  Public and live
-  Supports multiple datasets and models
-  Provides real-time predictions and visualization

---

## ğŸ”­ Future Work

- âœ… Feature fusion: Combine 2D and 3D features for robust classification  
- âœ… Apply on additional benchmark and real-world datasets  
- âœ… Scale to remote sensing applications in agriculture, city planning, and sustainability

---

## ğŸ¤ Contributors

- [Ommooley10](https://github.com/Ommooley10) 
- [Vaishnavi Paswan](https://github.com/vaishnavipaswan)
- [Vedika Agrawal](https://github.com/vedikagrawal)  
- Laxmikant Dubey

---

## ğŸ“ License

This project is open-source under the [MIT License](LICENSE).

---

## ğŸ“¬ Contact

For queries, suggestions, or collaborations, feel free to reach out via GitHub Issues or email.

